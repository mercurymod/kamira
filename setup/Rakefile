CONFIG = YAML.load_file("#{File.dirname(__FILE__)}/config.yml")

ENV['DB_NAME'] ||= CONFIG['db_name'] || 'kamira'

require 'rake'
require 'quality-measure-engine'
require 'health-data-standards'

# Set up Mongoid; note that this is a bundle:import dependency
task :environment do
  Mongoid.connect_to(ENV['DB_NAME'])
end

# Load up rake tasks for quality measure engine; this provides us with rake bundle:import
load Gem.loaded_specs['quality-measure-engine'].full_gem_path + '/lib/qme/tasks/bundle.rake'

desc "Download the appropriate value sets"
task :download_valuesets, [:username, :password] => :environment do |task, args|

  api = HealthDataStandards::Util::VSApi.new(CONFIG['ticket_url'], CONFIG['api_url'], args.username, args.password)

  RestClient.proxy = ENV["http_proxy"] || ENV["HTTP_PROXY"]
  api.get_proxy_ticket

  oids = QME::QualityMeasure.all.map { |id, measure| measure['oids'] }.flatten.compact.uniq

  oids.each do |oid|

    begin

      vs_data = api.get_valueset(oid)
      vs_data.force_encoding("utf-8") # deal with unicode in the vs response (even though string reports ASCII)

      xml = Nokogiri::XML(vs_data)
      xml.root.add_namespace_definition("vs","urn:ihe:iti:svs:2008")

      vs_element = xml.at_xpath("/vs:RetrieveValueSetResponse/vs:ValueSet")

      if vs_element && vs_element["ID"] == oid

        vs_element["id"] = oid
        vs = HealthDataStandards::SVS::ValueSet.load_from_xml(xml)

        # save unless there is a valueset with the given oid and version already in the db
        vs.save! unless HealthDataStandards::SVS::ValueSet.where(oid: vs.oid, version: vs.version).first

        puts "Loaded value set for #{oid}"

      else

        puts "ERROR: no value set found for #{oid}"

      end

    rescue => e

      puts "ERROR: #{e.message}"

    end

  end

end

desc "populate local database with complexity data calculated from bundle"
task :populate_measure_complexity, [:bundle_path,:type] => :environment do |task, args|
  load Gem.loaded_specs['health-data-standards'].full_gem_path + '/lib/hqmf-parser.rb'
  
  def eval_preconditions(preconds)
    child_score = preconds.select { |p| p.has_key? :preconditions }.map { |p| eval_preconditions(p[:preconditions]) }.sum # preconds.map{|p| p.has_key?(:preconditions) ? eval_preconditions(p[:preconditions]) : 0 }.sum
    child_score + preconds.size
  end

  pop_map = {
    'NUMER' => 'numerator',
    'DENOM' => 'denominator',
    'IPP' => 'population',
    'DENEXCEP' => 'exceptions',
    'DENEX' => 'exclusions'
  }

  Zip::ZipFile.open(args.bundle_path) do |zipfile|
    zipfile.entries.select { |e| e.name =~ %r{sources/#{args.type || 'ep'}/.*/hqmf1.xml} }.each do |entry|
      contents = zipfile.read entry
      hqmf = HQMF::Parser.parse(contents, HQMF::Parser::HQMF_VERSION_1).to_json
      population_criteria = hqmf[:population_criteria]
      hqmf[:populations].each_with_index do |pop, i|
        hqmf_id = hqmf[:hqmf_id]
        sub_id = (i + 'a'.getbyte(0)).chr if hqmf[:populations].size > 1 # (0 + 'a'.getbyte(0)).chr == 'a', which is good enough for our purposes
        measure_query = QME::QualityMeasure.get(hqmf_id, sub_id)
        measure = measure_query.first

        complexity = {}
        pop_map.each do |k, v|
          complexity[v] = if pop.has_key?(k) && (criteria = population_criteria[pop[k].to_sym]).has_key?(:preconditions)
            eval_preconditions(criteria[:preconditions])
          else
            1
          end
        end

        measure[:complexity] = complexity
        measure_query.update(measure)
      end
    end
  end
end